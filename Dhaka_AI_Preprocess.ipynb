{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dhaka_AI_Preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBuZCh4CyA2L"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import os, glob\n",
        "\n",
        "\n",
        "# Downloading teh dataset\n",
        "!gdown --id 1GIiqqmqEPSiGBb1MU1kIZG4q7BOIzqik\n",
        "!unzip traffic-dataset.zip; rm traffic-dataset.zip;\n",
        "clear_output()\n",
        "\n",
        "# There was .rar file inside .zip file. So we unzip them again !\n",
        "!unrar x train.rar\n",
        "!unrar x test1.rar\n",
        "clear_output()\n",
        "\n",
        "# Removing rar files that we no longer need. \n",
        "!rm train.rar\n",
        "!rm test1.rar\n",
        "\n",
        "# Removing unnecessary demo data folder from workspace.\n",
        "!rm -r sample_data\n",
        "\n",
        "# Renaming raw data folder to remove space. Trust me, it makes life a lot easier :D \n",
        "%mv 'Final Train Dataset' train_data_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoT7B3gVymLu"
      },
      "source": [
        "corrupt_files = ['231.jpg', '231.xml', 'Pias (359).PNG','Pias (359).xml', 'Pias (360).PNG', 'Pias (360).xml']\n",
        "\n",
        "%cd /content/train_data_raw/\n",
        "\n",
        "for file in corrupt_files:\n",
        "    file_path = os.path.join('/content/train_data_raw/', file)  \n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f'{file} is removed successfully')\n",
        "    else:\n",
        "        print(f'{file} is already deleted')\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9xPiTZDyvss"
      },
      "source": [
        "\"\"\"\n",
        "Thanks to @bjornstenger for his excellent code for converting the code from XML format to .txt format\n",
        "here is the original link of this cell of code.\n",
        "Original Link: https://github.com/bjornstenger/xml2yolo/blob/master/convert.py \n",
        "\"\"\"\n",
        "\n",
        "from xml.dom import minidom\n",
        "\n",
        "# Remember these number assigned. These are the label indexes which will be used in the training process.\n",
        "# Feel free to unfold to see what's inside \n",
        "lut={\"ambulance\": 0,\n",
        "     \"auto rickshaw\": 1,\n",
        "     \"bicycle\": 2,\n",
        "     \"bus\": 3,\n",
        "     \"car\": 4,\n",
        "     \"garbagevan\": 5,\n",
        "     \"human hauler\": 6,\n",
        "     \"minibus\": 7,\n",
        "     \"minivan\": 8,\n",
        "     \"motorbike\": 9,\n",
        "     \"pickup\": 10,\n",
        "     \"army vehicle\": 11,\n",
        "     \"policecar\": 12,\n",
        "     \"rickshaw\": 13,\n",
        "     \"scooter\": 14,\n",
        "     \"suv\": 15,\n",
        "     \"taxi\": 16,\n",
        "     \"three wheelers (CNG)\": 17,\n",
        "     \"truck\": 18,\n",
        "     \"van\": 19,\n",
        "     \"wheelbarrow\": 20\n",
        "     }\n",
        "\n",
        "label_count ={}\n",
        "\n",
        "print(f'Object Names: {list(lut.keys())}' )\n",
        "\n",
        "def convert_coordinates(size, box):\n",
        "    \"\"\"\n",
        "    This function converts the coordinates. \n",
        "    box: (xmin, ymin, xmax, ymax)\n",
        "    size: (width, height)\n",
        "\n",
        "    returns a touple where (x, y, height, width) of the boundary box\n",
        "    \"\"\"\n",
        "    dw = 1.0/size[0]\n",
        "    dh = 1.0/size[1]\n",
        "    x = (box[0]+box[1])/2.0\n",
        "    y = (box[2]+box[3])/2.0\n",
        "    w = box[1]-box[0]\n",
        "    h = box[3]-box[2]\n",
        "    x = x*dw\n",
        "    w = w*dw\n",
        "    y = y*dh\n",
        "    h = h*dh\n",
        "    return (x,y,w,h)\n",
        "\n",
        "\n",
        "def convert_xml2yolo(filelist, lut ):\n",
        "    \"\"\"\n",
        "    filelist: list of .xml file paths to convert to .txt file\n",
        "    lut: a dictionary containing class_name to class_index mapping\n",
        "    \"\"\"\n",
        "    for fname in filelist:\n",
        "        xmldoc = minidom.parse(fname)\n",
        "        fname_out = (fname[:-4]+'.txt')\n",
        "\n",
        "        with open(fname_out, \"w\") as f:\n",
        "            # print(f'processing{fname}')\n",
        "\n",
        "            itemlist = xmldoc.getElementsByTagName('object')\n",
        "            size = xmldoc.getElementsByTagName('size')[0]\n",
        "            width = int((size.getElementsByTagName('width')[0]).firstChild.data)\n",
        "            height = int((size.getElementsByTagName('height')[0]).firstChild.data)\n",
        "\n",
        "            for item in itemlist:\n",
        "                # get class label\n",
        "                classid =  (item.getElementsByTagName('name')[0]).firstChild.data\n",
        "                if classid in lut:\n",
        "                    label_str = str(lut[classid])\n",
        "                else:\n",
        "                    label_str = \"-1\"\n",
        "                    print (\"warning: label '%s' not in look-up table for file '%s'\" % classid, fname )\n",
        "                # get bbox coordinates\n",
        "                xmin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmin')[0]).firstChild.data\n",
        "                ymin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymin')[0]).firstChild.data\n",
        "                xmax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmax')[0]).firstChild.data\n",
        "                ymax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymax')[0]).firstChild.data\n",
        "                b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
        "                bb = convert_coordinates((width,height), b)\n",
        "                #print(bb)\n",
        "\n",
        "                label_count[classid] = label_count.get(classid, 0) + 1\n",
        "\n",
        "                f.write(label_str + \" \" + \" \".join([(\"%.6f\" % a) for a in bb]) + '\\n')\n",
        "        # print (\"wrote %s\" % fname_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOkX-cyry0Nt"
      },
      "source": [
        "# Reading Image file paths\n",
        "formats = ['jpg', 'jpeg', 'JPG', 'png']\n",
        "image_file_list = []\n",
        "for format in formats:\n",
        "    image_file_list.extend(glob.glob(f'/content/train_data_raw/*.{format}'))\n",
        "\n",
        "# Reading XML label file paths\n",
        "label_file_list_xml = glob.glob('/content/train_data_raw/*.xml')\n",
        "\n",
        "print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cNAHhpy2cs"
      },
      "source": [
        "# Converting .xml file to .txt file\n",
        "convert_xml2yolo(label_file_list_xml, lut)\n",
        "label_file_list_txt = glob.glob('/content/train_data_raw/*.txt')\n",
        "print(f'XML --> TXT files: {len(label_file_list_txt)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UCszpFgy42E"
      },
      "source": [
        "label_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZKTaQeJy780"
      },
      "source": [
        "from PIL import Image\n",
        "img_sizes = {}\n",
        "\n",
        "for fname in image_file_list:\n",
        "    img = Image.open(fname)\n",
        "    img_sizes[img.size] = img_sizes.get(img.size, 0) +1 \n",
        "img_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWMstjBbzN88"
      },
      "source": [
        "def resize_images(file_list, width = 1024, height = 1024, overwrite = True, save_dir = ''):\n",
        "    total_files = len(file_list)\n",
        "    idx = 1\n",
        "    for path in file_list:\n",
        "        img = Image.open(path)\n",
        "        img_resized = img.resize((width, height))\n",
        "        if overwrite:\n",
        "            img_resized.save(path)\n",
        "            filename = path.split('/')[-1] \n",
        "            print(f\"{idx}/{total_files}: {filename} {img.size}--> ({width}x{height})\")\n",
        "        else:\n",
        "            filename = path.split('/')[-1]\n",
        "            img_resized.save(save_dir + filename)\n",
        "            print(f'{filename} saved to {save_dir}')\n",
        "        idx +=1\n",
        "    clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2eyOUlPzST9"
      },
      "source": [
        "import random\n",
        "random.seed(1455)\n",
        "\n",
        "#randomply selecting the index of the files\n",
        "valid_set_index = random.sample(range(len(image_file_list)), 600)\n",
        "len(set(image_file_list)), len(set(label_file_list_txt)), len(valid_set_index)\n",
        "\n",
        "image_file_list = sorted(image_file_list)\n",
        "label_file_list_txt = sorted(label_file_list_txt)\n",
        "\n",
        "# sanity check of the image files and labels being in the same order\n",
        "print('Checking files concurrency')\n",
        "print(image_file_list[:5])\n",
        "print(label_file_list_txt[:5])\n",
        "\n",
        "# code to separate train and validation set\n",
        "valid_selected_images = []\n",
        "valid_selected_labels = []\n",
        "\n",
        "for index in valid_set_index: \n",
        "    valid_selected_images.append(image_file_list[index])\n",
        "    valid_selected_labels.append(label_file_list_txt[index])\n",
        "\n",
        "\n",
        "print('\\n\\nChecking files concurrency in validation set')\n",
        "print(valid_selected_images[:5])\n",
        "print(valid_selected_labels[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwCEJnhNzUg8"
      },
      "source": [
        "!mv test final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyQSAD2tzYNb"
      },
      "source": [
        "import shutil\n",
        "\n",
        "# Creating validation directory\n",
        "# valid_dir = '/content/valid/'\n",
        "valid_dir = '/content/test/'\n",
        "\n",
        "if os.path.exists(valid_dir):\n",
        "    print(f'Directory {valid_dir} already exists !')\n",
        "else: \n",
        "    os.makedirs(valid_dir)\n",
        "    print(f\"Directory {valid_dir} is created successfully!\") \n",
        "\n",
        "\n",
        "for idx in range(len(valid_selected_images)):\n",
        "    # moving image files\n",
        "    mypath = valid_selected_images[idx]\n",
        "    if os.path.exists(mypath):\n",
        "        filename = mypath.split('/')[-1]\n",
        "        shutil.move(mypath , valid_dir + filename)\n",
        "    else:\n",
        "        print(f'{mypath} not found')\n",
        "        \n",
        "    # moving label files\n",
        "    mypath = valid_selected_labels[idx]\n",
        "    if os.path.exists(mypath):\n",
        "        filename = mypath.split('/')[-1]\n",
        "        shutil.move(mypath , valid_dir + filename)\n",
        "    else:\n",
        "        print(f'{mypath} not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcLErD2UzaTE"
      },
      "source": [
        "# !mv train_data_raw train\n",
        "!mv train_data_raw obj "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjDXOeAzg3k"
      },
      "source": [
        "def lookup_image_file_paths(formats, dir):\n",
        "    \"\"\"\n",
        "    This function takes a specified set of formats and directory address to list all the filepaths\n",
        "    of the desired format in that directory\n",
        "    \"\"\"\n",
        "    filepaths = []\n",
        "    for format in formats:\n",
        "        filepaths.extend(glob.glob(f'{dir}*.{format}'))\n",
        "    return filepaths\n",
        "\n",
        "def make_txt_file(formats, dir):\n",
        "    \"\"\"\n",
        "    Formats the file names to write in the desired txt file\n",
        "    \"\"\"\n",
        "    filepaths = lookup_image_file_paths(formats, dir)\n",
        "    \n",
        "    filenames = [x.split('/')[-1] for x in filepaths]\n",
        "    txt_file_name = dir.split('/')[-2]\n",
        "\n",
        "    print(f'{txt_file_name} : {len(filepaths)} images')\n",
        "    with open(f'/content/metadata/{txt_file_name}.txt', 'w') as outfile:\n",
        "        for filename in filenames:\n",
        "            outfile.write(f'/mydrive/final/'+filename+'\\n')\n",
        "        outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EaNNCP9zkX7"
      },
      "source": [
        "# train_dir = '/content/train/'\n",
        "# valid_dir = '/content/valid/'\n",
        "# test_dir =  '/content/test/'\n",
        "train_dir = '/content/obj/'\n",
        "valid_dir = '/content/test/'\n",
        "test_dir =  '/content/final/'\n",
        "\n",
        "!mkdir metadata\n",
        "\n",
        "# Making the .txt file containing list of images. \n",
        "# make_txt_file(formats, dir = train_dir)\n",
        "make_txt_file(formats, dir = test_dir)\n",
        "# make_txt_file(formats, dir = valid_dir)\n",
        "\n",
        "# Writing the file traffic.names\n",
        "object_labels = list(lut.keys())\n",
        "with open('/content/metadata/traffic.names', 'w') as outfile:\n",
        "    for label in object_labels:\n",
        "        outfile.write(label + '\\n')\n",
        "    outfile.close()\n",
        "\n",
        "# Writing the file traffic.data\n",
        "data_config = f'classes=21\\ntrain=train.txt\\nvalid=valid.txt\\nnames=traffic.names'\n",
        "with open('/content/metadata/traffic.data', 'w') as outfile:\n",
        "    outfile.write(data_config + '\\n')\n",
        "    outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG4K-QGazoQ1"
      },
      "source": [
        "assert False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0tY7ZDbzrzE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjKzjE_pztjM"
      },
      "source": [
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "# !ls /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W82Bo7eZzvUs"
      },
      "source": [
        "!cp -r final '/mydrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb10F-nuz1WM"
      },
      "source": [
        "!cp '/content/metadata/final.txt' '/mydrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbiWmuCPXRn2"
      },
      "source": [
        "assert False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCz1L0QOz3bb"
      },
      "source": [
        "!ls /mydrive/yolov4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKj7cNe0z5SE"
      },
      "source": [
        "!zip -r obj.zip obj\n",
        "!zip -r test.zip test\n",
        "!cp obj.zip '/mydrive/yolov4'\n",
        "!cp test.zip '/mydrive/yolov4'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}